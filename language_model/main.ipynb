{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c721e3d1-ff60-42e4-b4f9-a7cb1c93242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train data\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "chromedriver_autoinstaller.install()\n",
    "wb = webdriver.Chrome()\n",
    "\n",
    "for i in range(23376, 100000):\n",
    "    try:\n",
    "        print(f\"Step {i}\\n\")\n",
    "        wb.get(f\"https://writing.stackexchange.com/questions/{i}\")\n",
    "        time.sleep(2)\n",
    "        open(\"train_data.txt\", \"a\").write(\"question: \"+wb.find_element(By.CLASS_NAME, 'question-hyperlink').text+\"\\n\"+(\"\\n\".join(wb.find_element(By.ID, 'question').text.split(\"\\n\")[2:])).split(\"\\nShare\\n\")[0]+\"\\nanswer: \"+wb.find_element(By.CLASS_NAME, 'answercell').text.split(\"\\nShare\\n\")[0]+\"\\n\\n\")\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b279cb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">31</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">28 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>n_head=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Number of attention heads</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29 </span>)                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>31 model = GPT2LMHeadModel(custom_config)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 # Load training data</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Loading training data...\"</span>)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">965</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 962 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 963 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, config):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 964 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(config)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 965 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transformer = GPT2Model(config)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 966 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 967 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 968 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Model parallel</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">683</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wpe = nn.Embedding(config.max_position_embeddings, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 682 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.drop = nn.Dropout(config.embd_pdrop)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 683 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.h = nn.ModuleList([GPT2Block(config, layer_idx=i) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(config.num  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 684 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_f = nn.LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm_epsilon)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 685 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 686 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Model parallel</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">683</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.wpe = nn.Embedding(config.max_position_embeddings, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 682 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.drop = nn.Dropout(config.embd_pdrop)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 683 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.h = nn.ModuleList([GPT2Block(config, layer_idx=i) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(config.num  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 684 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_f = nn.LayerNorm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, eps=config.layer_norm_epsilon)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 685 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 686 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Model parallel</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">369</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 366 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_dim = config.n_inner <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config.n_inner <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> * hidden_size     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 367 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_1 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 369 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn = GPT2Attention(config, layer_idx=layer_idx)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_2 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 372 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config.add_cross_attention:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">161</span> in         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.q_attn = Conv1D(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.c_attn = Conv1D(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.c_proj = Conv1D(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.embed_dim)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attn_dropout = nn.Dropout(config.attn_pdrop)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.resid_dropout = nn.Dropout(config.resid_pdrop)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">e\\local-packages\\Python37\\site-packages\\transformers\\pytorch_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">97</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, nf, nx):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.nf = nf                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 97 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight = nn.Parameter(torch.empty(nx, nf))                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias = nn.Parameter(torch.zeros(nf))                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>nn.init.normal_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, std=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.02</span>)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"font-weight: bold\">[</span>enforce fail at \n",
       "C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">72</span><span style=\"font-weight: bold\">]</span> data. \n",
       "DefaultCPUAllocator: not enough memory: you tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2359296</span> bytes.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m31\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m28 \u001b[0m\u001b[2m│   \u001b[0mn_head=\u001b[94m24\u001b[0m,  \u001b[2m# Number of attention heads\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m29 \u001b[0m)                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m30 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m31 model = GPT2LMHeadModel(custom_config)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m# Load training data\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mLoading training data...\u001b[0m\u001b[33m\"\u001b[0m)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m:\u001b[94m965\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 962 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 963 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, config):                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 964 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(config)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 965 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.transformer = GPT2Model(config)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 966 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=\u001b[94mFalse\u001b[0m)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 967 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 968 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Model parallel\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m:\u001b[94m683\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.wpe = nn.Embedding(config.max_position_embeddings, \u001b[96mself\u001b[0m.embed_dim)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 682 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.drop = nn.Dropout(config.embd_pdrop)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 683 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.h = nn.ModuleList([GPT2Block(config, layer_idx=i) \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(config.num  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 684 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_f = nn.LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm_epsilon)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 685 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 686 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Model parallel\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m:\u001b[94m683\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m<listcomp>\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.wpe = nn.Embedding(config.max_position_embeddings, \u001b[96mself\u001b[0m.embed_dim)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 682 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.drop = nn.Dropout(config.embd_pdrop)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 683 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.h = nn.ModuleList([GPT2Block(config, layer_idx=i) \u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(config.num  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 684 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_f = nn.LayerNorm(\u001b[96mself\u001b[0m.embed_dim, eps=config.layer_norm_epsilon)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 685 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 686 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Model parallel\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m:\u001b[94m369\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 366 \u001b[0m\u001b[2m│   │   \u001b[0minner_dim = config.n_inner \u001b[94mif\u001b[0m config.n_inner \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[94m4\u001b[0m * hidden_size     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 367 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 368 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_1 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 369 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.attn = GPT2Attention(config, layer_idx=layer_idx)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.ln_2 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 372 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m config.add_cross_attention:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m:\u001b[94m161\u001b[0m in         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__init__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 158 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.q_attn = Conv1D(\u001b[96mself\u001b[0m.embed_dim, \u001b[96mself\u001b[0m.embed_dim)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 159 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 160 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.c_attn = Conv1D(\u001b[94m3\u001b[0m * \u001b[96mself\u001b[0m.embed_dim, \u001b[96mself\u001b[0m.embed_dim)                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 161 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.c_proj = Conv1D(\u001b[96mself\u001b[0m.embed_dim, \u001b[96mself\u001b[0m.embed_dim)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 162 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 163 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.attn_dropout = nn.Dropout(config.attn_pdrop)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.resid_dropout = nn.Dropout(config.resid_pdrop)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Ivan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33me\\local-packages\\Python37\\site-packages\\transformers\\pytorch_utils.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92m__init__\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, nf, nx):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.nf = nf                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.weight = nn.Parameter(torch.empty(nx, nf))                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.bias = nn.Parameter(torch.zeros(nf))                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0mnn.init.normal_(\u001b[96mself\u001b[0m.weight, std=\u001b[94m0.02\u001b[0m)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0m\u001b[1m[\u001b[0menforce fail at \n",
       "C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:\u001b[1;36m72\u001b[0m\u001b[1m]\u001b[0m data. \n",
       "DefaultCPUAllocator: not enough memory: you tried to allocate \u001b[1;36m2359296\u001b[0m bytes.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fine_tune_model(model, tokenizer, train_data_chunk):\n",
    "    inputs = tokenizer(train_data_chunk, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    if input_ids.numel() == 0:\n",
    "        return  # Skip empty input chunks\n",
    "    input_shape = input_ids.shape\n",
    "    if len(input_shape) > 1:\n",
    "        input_ids = input_ids.view(-1, input_shape[-1])\n",
    "    else:\n",
    "        input_ids = input_ids.unsqueeze(0)  # Add a batch dimension if input is 1D\n",
    "    outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "custom_config = GPT2Config(\n",
    "    vocab_size=50257,  # Assuming you're using the default GPT-2 tokenizer's vocabulary size\n",
    "    n_positions=512,  # Maximum sequence length\n",
    "    n_ctx=512,  # Context size\n",
    "    n_embd=768,  # Dimensionality of the embeddings and hidden states\n",
    "    n_layer=128,  # Number of layers\n",
    "    n_head=24,  # Number of attention heads\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(custom_config)\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_data_path = \"train_data.txt\"\n",
    "train_data = open(train_data_path, 'r', encoding=\"utf-8\", errors='ignore').read().strip().split(\"\\n\\n\")\n",
    "train_data_lines = len(train_data)\n",
    "\n",
    "# Preprocess data and fine-tune the model\n",
    "print(\"Preprocessing data and fine-tuning model...\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "progress_bar = tqdm(total=train_data_lines, desc=\"Fine-tuning Progress\")\n",
    "for chunk in train_data:\n",
    "    fine_tune_model(model, tokenizer, chunk)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Optionally, save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_gpt2\")\n",
    "\n",
    "print(\"Fine-tuning completed and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdf1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  how are you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "how are you going to do it?\"\n",
      "\n",
      "\"I'm going to do it,\" she said. \"I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going to do it. I'm going\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  can you give me a python code example about requests?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "can you give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can give me a python code example about requests?\n",
      "\n",
      "I'm not sure if you can\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  give me a python code about requests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "give me a python code about requests and responses.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not, but I'm sure it's a good idea.\n",
      "\n",
      "I'm not sure if this is a good idea or not,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  give me python code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "give me python code to run it.\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pipeline.py\n",
      "\n",
      "$ python -m python-pip\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  What is your name?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "What is your name?\n",
      "\n",
      "I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a long time. I'm a guy who's been doing this for a\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Q:  你知道我是誰嗎？\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "你知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是誰嗎？。\n",
      "\n",
      "知道我是\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"fine_tuned_gpt2\")\n",
    "\n",
    "def ask_question(question):\n",
    "    input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "    output_ids = model.generate(input_ids, max_length=200, num_return_sequences=1)\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "question = \"\"\n",
    "while question != \"exit\":\n",
    "    question = input(\"Q: \")\n",
    "    answer = ask_question(question)\n",
    "    print(\"A:\\n\"+answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a9792-ab4a-404b-902a-6ba91948eac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
